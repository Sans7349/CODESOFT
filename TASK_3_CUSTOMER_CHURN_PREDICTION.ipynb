{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq/qPRnM1lEJTB7Td4+O1H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sans7349/CODESOFT/blob/My-tasks/TASK_3_CUSTOMER_CHURN_PREDICTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Churn_Modelling.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"First few rows of the dataset:\\n\", data.head())\n",
        "\n",
        "# Display dataset information\n",
        "print(\"\\nDataset information:\\n\")\n",
        "data.info()\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values:\\n\", data.isnull().sum())\n",
        "\n",
        "# Display basic statistics\n",
        "print(\"\\nBasic statistics:\\n\", data.describe())\n",
        "\n",
        "print(\"___________________________________________________________________________________________________________________________________________________\")\n",
        "\n",
        "\n",
        "# Data preprocessing\n",
        "# Drop irrelevant columns\n",
        "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoder_geography = LabelEncoder()\n",
        "label_encoder_gender = LabelEncoder()\n",
        "\n",
        "data['Geography'] = label_encoder_geography.fit_transform(data['Geography'])\n",
        "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
        "\n",
        "# Define features and target\n",
        "X = data.drop('Exited', axis=1)\n",
        "y = data['Exited']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model building\n",
        "# Logistic Regression\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "\n",
        "# Random Forest\n",
        "rand_forest = RandomForestClassifier(random_state=42)\n",
        "rand_forest.fit(X_train, y_train)\n",
        "y_pred_rand_forest = rand_forest.predict(X_test)\n",
        "\n",
        "# Gradient Boosting\n",
        "grad_boost = GradientBoostingClassifier(random_state=42)\n",
        "grad_boost.fit(X_train, y_train)\n",
        "y_pred_grad_boost = grad_boost.predict(X_test)\n",
        "\n",
        "# Model evaluation\n",
        "def evaluate_model(y_test, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nLogistic Regression:\")\n",
        "evaluate_model(y_test, y_pred_log_reg)\n",
        "print(\"___________________________________________________________________________________________________________________________________________________\")\n",
        "\n",
        "\n",
        "print(\"\\nRandom Forest:\")\n",
        "evaluate_model(y_test, y_pred_rand_forest)\n",
        "print(\"___________________________________________________________________________________________________________________________________________________\")\n",
        "\n",
        "\n",
        "print(\"\\nGradient Boosting:\")\n",
        "evaluate_model(y_test, y_pred_grad_boost)\n",
        "print(\"___________________________________________________________________________________________________________________________________________________\")\n",
        "\n",
        "\n",
        "# Assuming Gradient Boosting performs best, use it for prediction\n",
        "best_model = grad_boost\n",
        "\n",
        "# Save the encoding mappings\n",
        "geography_mapping = dict(zip(label_encoder_geography.classes_, label_encoder_geography.transform(label_encoder_geography.classes_)))\n",
        "gender_mapping = dict(zip(label_encoder_gender.classes_, label_encoder_gender.transform(label_encoder_gender.classes_)))\n",
        "\n",
        "# Predict churn for new data (example)\n",
        "new_customer_data = pd.DataFrame({\n",
        "    'CreditScore': [600],\n",
        "    'Geography': [geography_mapping['France']],\n",
        "    'Gender': [gender_mapping['Female']],\n",
        "    'Age': [40],\n",
        "    'Tenure': [5],\n",
        "    'Balance': [60000],\n",
        "    'NumOfProducts': [2],\n",
        "    'HasCrCard': [1],\n",
        "    'IsActiveMember': [1],\n",
        "    'EstimatedSalary': [50000]\n",
        "})\n",
        "\n",
        "# Standardize the new customer data\n",
        "new_customer_data = scaler.transform(new_customer_data)\n",
        "\n",
        "# Predict churn\n",
        "churn_prediction = best_model.predict(new_customer_data)\n",
        "print(\"\\nChurn prediction for the new customer:\", \"Yes\" if churn_prediction[0] == 1 else \"No\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nhsOClMdhb4",
        "outputId": "2bc6d422-6bbd-4482-89e7-3047fc7d5acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the dataset:\n",
            "    RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
            "0          1    15634602  Hargrave          619    France  Female   42   \n",
            "1          2    15647311      Hill          608     Spain  Female   41   \n",
            "2          3    15619304      Onio          502    France  Female   42   \n",
            "3          4    15701354      Boni          699    France  Female   39   \n",
            "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
            "\n",
            "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
            "0       2       0.00              1          1               1   \n",
            "1       1   83807.86              1          0               1   \n",
            "2       8  159660.80              3          1               0   \n",
            "3       1       0.00              2          0               0   \n",
            "4       2  125510.82              1          1               1   \n",
            "\n",
            "   EstimatedSalary  Exited  \n",
            "0        101348.88       1  \n",
            "1        112542.58       0  \n",
            "2        113931.57       1  \n",
            "3         93826.63       0  \n",
            "4         79084.10       0  \n",
            "\n",
            "Dataset information:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n",
            "\n",
            "Missing values:\n",
            " RowNumber          0\n",
            "CustomerId         0\n",
            "Surname            0\n",
            "CreditScore        0\n",
            "Geography          0\n",
            "Gender             0\n",
            "Age                0\n",
            "Tenure             0\n",
            "Balance            0\n",
            "NumOfProducts      0\n",
            "HasCrCard          0\n",
            "IsActiveMember     0\n",
            "EstimatedSalary    0\n",
            "Exited             0\n",
            "dtype: int64\n",
            "\n",
            "Basic statistics:\n",
            "          RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
            "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
            "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
            "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
            "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
            "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
            "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
            "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
            "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
            "\n",
            "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
            "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
            "mean    76485.889288       1.530200      0.70550        0.515100   \n",
            "std     62397.405202       0.581654      0.45584        0.499797   \n",
            "min         0.000000       1.000000      0.00000        0.000000   \n",
            "25%         0.000000       1.000000      0.00000        0.000000   \n",
            "50%     97198.540000       1.000000      1.00000        1.000000   \n",
            "75%    127644.240000       2.000000      1.00000        1.000000   \n",
            "max    250898.090000       4.000000      1.00000        1.000000   \n",
            "\n",
            "       EstimatedSalary        Exited  \n",
            "count     10000.000000  10000.000000  \n",
            "mean     100090.239881      0.203700  \n",
            "std       57510.492818      0.402769  \n",
            "min          11.580000      0.000000  \n",
            "25%       51002.110000      0.000000  \n",
            "50%      100193.915000      0.000000  \n",
            "75%      149388.247500      0.000000  \n",
            "max      199992.480000      1.000000  \n",
            "___________________________________________________________________________________________________________________________________________________\n",
            "\n",
            "Logistic Regression:\n",
            "Accuracy: 0.815\n",
            "Confusion Matrix:\n",
            " [[1559   48]\n",
            " [ 322   71]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.97      0.89      1607\n",
            "           1       0.60      0.18      0.28       393\n",
            "\n",
            "    accuracy                           0.81      2000\n",
            "   macro avg       0.71      0.58      0.59      2000\n",
            "weighted avg       0.78      0.81      0.77      2000\n",
            "\n",
            "___________________________________________________________________________________________________________________________________________________\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.8645\n",
            "Confusion Matrix:\n",
            " [[1545   62]\n",
            " [ 209  184]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92      1607\n",
            "           1       0.75      0.47      0.58       393\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.81      0.71      0.75      2000\n",
            "weighted avg       0.85      0.86      0.85      2000\n",
            "\n",
            "___________________________________________________________________________________________________________________________________________________\n",
            "\n",
            "Gradient Boosting:\n",
            "Accuracy: 0.8655\n",
            "Confusion Matrix:\n",
            " [[1547   60]\n",
            " [ 209  184]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92      1607\n",
            "           1       0.75      0.47      0.58       393\n",
            "\n",
            "    accuracy                           0.87      2000\n",
            "   macro avg       0.82      0.72      0.75      2000\n",
            "weighted avg       0.86      0.87      0.85      2000\n",
            "\n",
            "___________________________________________________________________________________________________________________________________________________\n",
            "\n",
            "Churn prediction for the new customer: No\n"
          ]
        }
      ]
    }
  ]
}